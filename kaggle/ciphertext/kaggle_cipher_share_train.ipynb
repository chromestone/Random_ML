{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_cipher_share_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "GhYU0keO-31Z",
        "AmL6I9pkrcme"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "p5mn-1-hrgwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "2i7oEvjkIJTu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "not related to model but good to put at the top\n",
        "\n",
        "restart runtime after"
      ]
    },
    {
      "metadata": {
        "id": "RmXjiRvMIIoO",
        "colab_type": "code",
        "outputId": "f836d7eb-ba59-48eb-bdc8-ce9d20f20f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "#some dtype problem that came out only in 0.23 for get_dummies\n",
        "!pip3 install --upgrade pandas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 8.9MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "Successfully installed pandas-0.23.4\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [pandas]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1rRNedTE6JKt",
        "colab_type": "code",
        "outputId": "a6a93faa-83c4-4080-e8d2-ab3a2d687111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0tZdpnQA6cnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73xuW1JW6ejy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.layers as KL\n",
        "#from keras import losses\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4sDi08_p6klI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv1d_bn(x,\n",
        "              filters,\n",
        "              kernel_size,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              use_bias=True,\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "    Obtained from:\n",
        "    github.com/keras-team/keras-applications/blob/master/keras_applications/inception_resnet_v2.py\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        kernel_size: kernel size as in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        activation: activation in `Conv2D`.\n",
        "        use_bias: whether to use a bias in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_ac'` for the activation\n",
        "            and `name + '_bn'` for the batch norm layer.\n",
        "    # Returns\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    x = KL.Conv1D(filters,\n",
        "                  kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding=padding,\n",
        "                  use_bias=use_bias,\n",
        "                  name=name)(x)\n",
        "\n",
        "    bn_name = None if name is None else name + '_bn'\n",
        "    # training set to False according to some code for Mask RCNN by matterport\n",
        "    x = KL.BatchNormalization(axis=2,\n",
        "                              scale=False,\n",
        "                              name=bn_name)(x, training=False)\n",
        "    if activation is not None:\n",
        "        ac_name = None if name is None else name + '_ac'\n",
        "        x = KL.Activation(activation, name=ac_name)(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y6Oy4KkM6rU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# p_size usually 3 in our facenet case\n",
        "def inception_tower_4_pool(x, f1x1, f3x3r, f3x3, f5x5r, f5x5, p_size, f1x1p, prefix):\n",
        "\n",
        "    tower_1 = conv1d_bn(x, f1x1, (1,), name=prefix + '_conv_1')\n",
        "\n",
        "    tower_2 = conv1d_bn(x, f3x3r, (1,), name=prefix + '_conv_2')\n",
        "    tower_2 = conv1d_bn(tower_2, f3x3, (3, ), name=prefix + 'conv_3')\n",
        "\n",
        "    tower_3 = conv1d_bn(x, f5x5r, (1,), name=prefix + '_conv_4')\n",
        "    tower_3 = conv1d_bn(tower_3, f5x5, (5, ), name=prefix + 'conv_5')\n",
        "\n",
        "    tower_4 = KL.MaxPooling1D((p_size,), strides=(1,), padding='same', name=prefix + '_max_pool')(x)\n",
        "    tower_4 = conv1d_bn(tower_4, f1x1p, (1,), name=prefix + '_conv_6')\n",
        "\n",
        "    return KL.concatenate([tower_1, tower_2, tower_3, tower_4], axis=2, name=prefix + '_cat')\n",
        "  \n",
        "def inception_tower_4_l2(x, f1x1, f3x3r, f3x3, f5x5r, f5x5, f1x1p, prefix):\n",
        "\n",
        "    tower_1 = conv1d_bn(x, f1x1, (1,), name=prefix + '_conv_1')\n",
        "\n",
        "    tower_2 = conv1d_bn(x, f3x3r, (1,), name=prefix + '_conv_2')\n",
        "    tower_2 = conv1d_bn(tower_2, f3x3, (3, ), name=prefix + 'conv_3')\n",
        "\n",
        "    tower_3 = conv1d_bn(x, f5x5r, (1,), name=prefix + '_conv_4')\n",
        "    tower_3 = conv1d_bn(tower_3, f5x5, (5, ), name=prefix + 'conv_5')\n",
        "\n",
        "    tower_4 = KL.Lambda(K.l2_normalize, name=prefix + '_L2')(x)\n",
        "    tower_4 = conv1d_bn(tower_4, f1x1p, (1,), name=prefix + '_conv_6')\n",
        "\n",
        "    return KL.concatenate([tower_1, tower_2, tower_3, tower_4], axis=2, name=prefix + '_cat')\n",
        "\n",
        "# note that strides for max pool is 2 here and without dim. reduction\n",
        "# and 3x3 & 5x5 also have stride 2\n",
        "# and there is no conv_1 (or conv_6)\n",
        "def inception_tower_3(x, f3x3r, f3x3, f5x5r, f5x5, p_size, prefix):\n",
        "\n",
        "    tower_2 = conv1d_bn(x, f3x3r, (1,), name=prefix + '_conv_2')\n",
        "    tower_2 = conv1d_bn(tower_2, f3x3, (3, ), strides=(2,), name=prefix + 'conv_3')\n",
        "\n",
        "    tower_3 = conv1d_bn(x, f5x5r, (1,), name=prefix + '_conv_4')\n",
        "    tower_3 = conv1d_bn(tower_3, f5x5, (5, ), strides=(2,), name=prefix + 'conv_5')\n",
        "\n",
        "    tower_4 = KL.MaxPooling1D((p_size,), strides=(2,), padding='same', name=prefix + '_max_pool')(x)\n",
        "\n",
        "    return KL.concatenate([tower_2, tower_3, tower_4], axis=2, name=prefix + '_cat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ubB-kIKwn26c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def local_norm_1d(x):\n",
        "  \n",
        "  x = K.expand_dims(x, axis=0)\n",
        "  x = tf.nn.local_response_normalization(x)\n",
        "  return K.squeeze(x, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-IUbRwG_7JK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_in = KL.Input((300, 1), name='the_input')\n",
        "target_in = KL.Input((20,), name='target_in')\n",
        "diff_in = KL.Input((1,), name='diff_in')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xg3VldTU6vBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = KL.ZeroPadding1D(10, name='padding_1')(model_in)\n",
        "\n",
        "x = conv1d_bn(x, 64, (7,), strides=2, name='conv_1')\n",
        "\n",
        "x = KL.MaxPooling1D(3, strides=2, padding='same', name='max_pool_1')(x)\n",
        "x = KL.Lambda(local_norm_1d, name='norm_1')(x)\n",
        "\n",
        "x = conv1d_bn(x, 64, (1,), name='ncptn_1_conv_1')\n",
        "x = conv1d_bn(x, 192, (3,), name='ncptn_1_conv_2')\n",
        "x = conv1d_bn(x, 64, (1,), name='ncptn_2_conv_1')\n",
        "x = conv1d_bn(x, 192, (3,), name='ncptn_2_conv_2')\n",
        "\n",
        "x = KL.Lambda(local_norm_1d, name='norm_2')(x)\n",
        "x = KL.MaxPooling1D(3, strides=2, padding='same', name='max_pool_2')(x)\n",
        "\n",
        "x = inception_tower_4_pool(x, 64, 96, 128, 16, 32, 3, 32, prefix='ncptn_3a')\n",
        "x = inception_tower_4_l2(  x, 64, 96, 128, 32, 64,    64, prefix='ncptn_3b')\n",
        "x = inception_tower_3(     x,    128, 256, 32, 64, 3,     prefix='ncptn_3c')\n",
        "\n",
        "x = inception_tower_4_l2(x, 256,  96, 192, 32, 64, 128, prefix='ncptn_4a')\n",
        "x = inception_tower_4_l2(x, 224, 112, 224, 32, 64, 128, prefix='ncptn_4b')\n",
        "x = inception_tower_4_l2(x, 192, 128, 256, 32, 64, 128, prefix='ncptn_4c')\n",
        "x = inception_tower_4_l2(x, 160, 144, 288, 32, 64, 128, prefix='ncptn_4d')\n",
        "x = inception_tower_3(   x,      160, 256, 64,128,    3,prefix='ncptn_4e')\n",
        "\n",
        "x = inception_tower_4_l2(  x, 384, 192, 384, 48, 128,    128, prefix='ncptn_5a')\n",
        "x = inception_tower_4_pool(x, 384, 192, 384, 48, 128, 3, 128, prefix='ncptn_5b')\n",
        "\n",
        "x = KL.AveragePooling1D(10, name='avg_pool_1')(x)\n",
        "x = KL.Flatten()(x)\n",
        "\n",
        "# inception v1 does dropout, described in \"Going Deeper with Conv...\" is 40%,\n",
        "# but tf impl. defaults to 20%\n",
        "x = KL.Dropout(0.4)(x)\n",
        "\n",
        "d1 = KL.Dense(20, name='dense_1')(x)\n",
        "d2 = KL.Dense(20, name='dense_2')(x)\n",
        "d3 = KL.Dense(20, name='dense_3')(x)\n",
        "d4 = KL.Dense(20, name='dense_4')(x)\n",
        "\n",
        "# d1 = KL.Dense(20, activation='softmax', name='dense_1')(x)\n",
        "# d2 = KL.Dense(20, activation='softmax', name='dense_2')(x)\n",
        "# d3 = KL.Dense(20, activation='softmax', name='dense_3')(x)\n",
        "# d4 = KL.Dense(20, activation='softmax', name='dense_4')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K--fRWDO3qQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_loss_fn(y_true, y_pred, difficulties, diff_level):\n",
        "\n",
        "  indices = tf.where(tf.equal(difficulties, diff_level))\n",
        "\n",
        "  actual = tf.gather(y_true, indices)\n",
        "  predict = tf.gather(y_pred, indices)\n",
        "\n",
        "  return tf.losses.softmax_cross_entropy(actual, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-1Kqzx-5W5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_1 = KL.Lambda(lambda x: model_loss_fn(*x, 1), name='loss_1')(\n",
        "                   [target_in, d1, diff_in])\n",
        "loss_2 = KL.Lambda(lambda x: model_loss_fn(*x, 2), name='loss_2')(\n",
        "                   [target_in, d2, diff_in])\n",
        "loss_3 = KL.Lambda(lambda x: model_loss_fn(*x, 3), name='loss_3')(\n",
        "                   [target_in, d3, diff_in])\n",
        "loss_4 = KL.Lambda(lambda x: model_loss_fn(*x, 4), name='loss_4')(\n",
        "                   [target_in, d4, diff_in])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "leWPbG4S6dnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = [model_in, target_in, diff_in]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dh4IMnWr3ebM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outputs = [d1, d2, d3, d4, loss_1, loss_2, loss_3, loss_4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsB0nJ2s_yGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xk4PBCIg8SYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add_loss(loss_1)\n",
        "model.add_loss(loss_2)\n",
        "model.add_loss(loss_3)\n",
        "model.add_loss(loss_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GhYU0keO-31Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualization"
      ]
    },
    {
      "metadata": {
        "id": "1IAsVqv48YG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Lh4RFfD-zTG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8XxY_c7-2VX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FD2TzoaH-5vd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmL6I9pkrcme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## sanity check"
      ]
    },
    {
      "metadata": {
        "id": "Wm2VQStfw4iG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "loss fn 2.0 test edge case"
      ]
    },
    {
      "metadata": {
        "id": "fj0_wzv8xOuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYcIRhRPxQ_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yw0ROJI3w5m0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_loss_fn(y_true, y_pred, difficulties, diff_level):\n",
        "\n",
        "  indices = tf.where(tf.equal(difficulties, diff_level))\n",
        "\n",
        "  actual = tf.gather(y_true, indices)\n",
        "  predict = tf.gather(y_pred, indices)\n",
        "\n",
        "  return tf.losses.softmax_cross_entropy(actual, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IjajXHXbxmaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6lD1sYpJxOPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "foo_true = np.array([[[0, 1, 0, 0],\n",
        "                     [1, 0, 0, 0],\n",
        "                     [0, 0, 0, 1],\n",
        "                     [0, 0, 1, 0]\n",
        "                    ]], dtype=np.float32)\n",
        "foo_pred = np.array([[[0, 0, 1, 0],\n",
        "                     [0, 0, 0, 1],\n",
        "                     [1, 0, 0, 0],\n",
        "                     [0, 1, 0, 0]\n",
        "                    ]], dtype=np.float32)\n",
        "foo_diff = np.array([0,\n",
        "                     1,\n",
        "                     0,\n",
        "                     1\n",
        "                    ], dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNnIDcI6xZnJ",
        "colab_type": "code",
        "outputId": "3a8aaf98-7c29-4796-cbd6-438a94340697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_loss_fn(foo_true, foo_pred, foo_diff, np.array([2], dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=73, shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "ipwow801zH9O",
        "colab_type": "code",
        "outputId": "8bd4b933-102e-400e-88c4-78d107c916f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "true = ([0]*19)\n",
        "true.append(1)\n",
        "pred = [1]\n",
        "pred.extend([0]*19)\n",
        "tf.losses.softmax_cross_entropy(np.array(true, dtype=np.float32),\n",
        "                                np.array(pred, dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=133, shape=(), dtype=float32, numpy=3.0781546>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "LwCYGapsbG3S",
        "colab_type": "code",
        "outputId": "0b82bf1a-8c44-468f-df38-a355bebb1bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "true = ([0]*19)\n",
        "true.append(1)\n",
        "pred = [0.05]*20\n",
        "tf.losses.softmax_cross_entropy(np.array(true, dtype=np.float32),\n",
        "                                np.array(pred, dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=199, shape=(), dtype=float32, numpy=2.9957323>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "37sVU4v6w3Az",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "loss fn 1 test 2"
      ]
    },
    {
      "metadata": {
        "id": "Aogn1zMgP-j4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfPPhjHEQC8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLEy8mrkP9HT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_loss_fn(y_true, y_pred, difficulties, diff_level):\n",
        "\n",
        "  indices = tf.where(tf.equal(difficulties, diff_level))\n",
        "  \n",
        "#   tf.print(indices)\n",
        "  \n",
        "  actual = tf.gather(y_true, indices)\n",
        "  predict = tf.gather(y_pred, indices)\n",
        "  \n",
        "#   tf.print(actual)\n",
        "#   tf.print(predict)\n",
        "  \n",
        "  return losses.categorical_crossentropy(actual, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0_SGUfxQSfj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3FcurSQIQGGo",
        "colab_type": "code",
        "outputId": "6b44d44d-74f3-40e3-998a-25e24cbbc9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.losses.softmax_cross_entropy(np.ones((2, 20)), np.ones((2, 20)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=67, shape=(), dtype=float64, numpy=59.91464614868164>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "O74a6wnTRaoo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "foo_true = np.array([[[0, 1, 0, 0],\n",
        "                     [1, 0, 0, 0],\n",
        "                     [0, 0, 0, 1],\n",
        "                     [0, 0, 1, 0]\n",
        "                    ]], dtype=np.float32)\n",
        "foo_pred = np.array([[[0, 0, 1, 0],\n",
        "                     [0, 0, 0, 1],\n",
        "                     [1, 0, 0, 0],\n",
        "                     [0, 1, 0, 0]\n",
        "                    ]], dtype=np.float32)\n",
        "foo_diff = np.array([0,\n",
        "                     1,\n",
        "                     0,\n",
        "                     1\n",
        "                    ], dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfhedJxsRdyv",
        "colab_type": "code",
        "outputId": "28852532-93ca-49d5-e17b-ed4a876f1576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "model_loss_fn(foo_true, foo_pred, foo_diff, np.array([0], dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=91, shape=(2, 1), dtype=float32, numpy=\n",
              "array([[16.118095],\n",
              "       [16.118095]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "IdCWeaubQGRq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "output shape"
      ]
    },
    {
      "metadata": {
        "id": "pG98hrAmOdEa",
        "colab_type": "code",
        "outputId": "d4153548-c874-4346-cf66-b8b3a6713ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.get_layer('dense_1').output_shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "RAgOO48jPeyx",
        "colab_type": "code",
        "outputId": "8c48830e-2bf4-42c1-9801-0b5fd646b8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.get_layer('target_in').output_shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "t6u6V7xaPQdH",
        "colab_type": "code",
        "outputId": "f3847b64-bce2-404c-bd56-22d21cb248b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.get_layer('loss_1').output_shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "7pyGnBaMMGQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yajCwnjJL4cS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[model_in], outputs=[d1, d2, d3, d4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpww5N8lMExE",
        "colab_type": "code",
        "outputId": "9d67ca7a-4f1f-4a50-8fd7-81509d0000a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(np.ones((1, 300, 1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[0.0501996 , 0.05014166, 0.04990169, 0.04997953, 0.04987779,\n",
              "          0.0500317 , 0.04982448, 0.05004711, 0.04973657, 0.04987436,\n",
              "          0.05002686, 0.05002549, 0.05023536, 0.04996005, 0.04973293,\n",
              "          0.05017341, 0.05003966, 0.0502243 , 0.04983046, 0.05013706]]],\n",
              "       dtype=float32),\n",
              " array([[[0.04963082, 0.04970811, 0.05015945, 0.05035815, 0.04988367,\n",
              "          0.04997969, 0.05012528, 0.04970011, 0.04998784, 0.05003733,\n",
              "          0.05018548, 0.05027582, 0.05009138, 0.04966076, 0.05031439,\n",
              "          0.04969691, 0.05009257, 0.05000971, 0.05032682, 0.04977572]]],\n",
              "       dtype=float32),\n",
              " array([[[0.05024128, 0.04980202, 0.04980695, 0.05012323, 0.04954685,\n",
              "          0.05000426, 0.05007407, 0.0498806 , 0.05022278, 0.05044633,\n",
              "          0.04988617, 0.05005704, 0.04993817, 0.04992321, 0.0501009 ,\n",
              "          0.05022063, 0.05001197, 0.05021008, 0.04999688, 0.04950662]]],\n",
              "       dtype=float32),\n",
              " array([[[0.0502107 , 0.04990887, 0.0502199 , 0.04971565, 0.05008033,\n",
              "          0.04980648, 0.0501155 , 0.04958036, 0.04968542, 0.05014165,\n",
              "          0.04996767, 0.05030048, 0.05010387, 0.05018206, 0.04996793,\n",
              "          0.04992578, 0.050023  , 0.05012171, 0.04970042, 0.05024218]]],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "e6PyYcLPa-7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "start loss test"
      ]
    },
    {
      "metadata": {
        "id": "yx6YeOlAeQ0y",
        "colab_type": "code",
        "outputId": "0e42ca59-8bea-4741-a445-e6699a1fe46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nrbRuBwqs0k4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84btjEgvbFrl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KT0J7OwhYp76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_loss_fn(y_true, y_pred, difficulties, diff_level):\n",
        "  \n",
        "  indices = tf.where(difficulties == diff_level)\n",
        "  \n",
        "  actual = tf.gather(y_true, indices)\n",
        "  predict = tf.gather(y_pred, indices)\n",
        "  \n",
        "  return losses.categorical_crossentropy(actual, predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zsl8ftsMa6y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDWmmaMSa-Cw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "foo_true = np.array([[0, 1, 0, 0],\n",
        "                     [1, 0, 0, 0],\n",
        "                     [0, 0, 0, 1],\n",
        "                     [0, 0, 1, 0]\n",
        "                    ], dtype=np.float32)\n",
        "foo_pred = np.array([[0, 0, 1, 0],\n",
        "                     [0, 0, 0, 1],\n",
        "                     [1, 0, 0, 0],\n",
        "                     [0, 1, 0, 0]\n",
        "                    ], dtype=np.float32)\n",
        "foo_diff = np.array([0,\n",
        "                     1,\n",
        "                     0,\n",
        "                     1\n",
        "                    ], dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRkb3ynubQVJ",
        "colab_type": "code",
        "outputId": "968ee970-9622-4bc8-8427-2551d6d5fda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "model_loss_fn(foo_true, foo_pred, foo_diff, np.array([0], dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=80, shape=(2, 1), dtype=float32, numpy=\n",
              "array([[16.118095],\n",
              "       [16.118095]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "uFmYGjrNbQfD",
        "colab_type": "code",
        "outputId": "0faaca8c-8a32-480d-f12c-db4be5b7eae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "model_loss_fn(foo_true, foo_pred, foo_diff, np.array([1], dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=102, shape=(2, 1), dtype=float32, numpy=\n",
              "array([[16.118095],\n",
              "       [16.118095]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "BobLpOO-a8wE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "end loss test"
      ]
    },
    {
      "metadata": {
        "id": "rtGbHhvFAK4N",
        "colab_type": "code",
        "outputId": "edaa0d52-dbde-409b-ca5d-3bfb1ce3b158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.name)\n",
        "  print(layer.output_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_4\n",
            "(None, 300, 1)\n",
            "padding_1\n",
            "(None, 308, 1)\n",
            "conv_1\n",
            "(None, 154, 64)\n",
            "conv_1_bn\n",
            "(None, 154, 64)\n",
            "conv_1_ac\n",
            "(None, 154, 64)\n",
            "max_pool_1\n",
            "(None, 77, 64)\n",
            "norm_1\n",
            "(None, 77, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9D5lXKfMpeWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_in = KL.Input((2, 2), name='the_input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzvR6R-sARxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = KL.Lambda(local_norm_1d, name='norm_1')(model_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vxD8wOuWo_2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=model_in, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVH-0dOwpC7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMIxusnSpHBQ",
        "colab_type": "code",
        "outputId": "256f70ce-d5fe-4fdb-c0fc-3b1a1d5372bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(np.ones((2,2,2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.57735026, 0.57735026],\n",
              "        [0.57735026, 0.57735026]],\n",
              "\n",
              "       [[0.57735026, 0.57735026],\n",
              "        [0.57735026, 0.57735026]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2CC9gBIpoEd",
        "colab_type": "code",
        "outputId": "57b6761b-a4dc-4175-9ecc-18219f5c649e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "foo = np.ones((2,2,2))\n",
        "foo[0][0][0] = 0\n",
        "foo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1.],\n",
              "        [1., 1.]],\n",
              "\n",
              "       [[1., 1.],\n",
              "        [1., 1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "vivm95v6pLYo",
        "colab_type": "code",
        "outputId": "a3536551-06c6-41ba-f99f-a03614ce7000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(foo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        , 0.7071067 ],\n",
              "        [0.57735026, 0.57735026]],\n",
              "\n",
              "       [[0.57735026, 0.57735026],\n",
              "        [0.57735026, 0.57735026]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "TfpVuPnmrBj-",
        "colab_type": "code",
        "outputId": "36527cad-d68a-4b11-877c-f974adc2b726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "foo = np.ones((2,2,2))\n",
        "foo[0][0][0] = 0\n",
        "foo[0][1][0] = 0\n",
        "foo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1.],\n",
              "        [0., 1.]],\n",
              "\n",
              "       [[1., 1.],\n",
              "        [1., 1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "JU4qBdiwrFAj",
        "colab_type": "code",
        "outputId": "75294eed-24d0-4c17-dd38-2773ab60d697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(foo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        , 0.7071067 ],\n",
              "        [0.        , 0.7071067 ]],\n",
              "\n",
              "       [[0.57735026, 0.57735026],\n",
              "        [0.57735026, 0.57735026]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "Tg8klK5dAktT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data"
      ]
    },
    {
      "metadata": {
        "id": "oEiNHvw4H2A1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## io"
      ]
    },
    {
      "metadata": {
        "id": "SzQOtwzoAl9T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8R-Wk8fgAqII",
        "colab_type": "code",
        "outputId": "b2402252-cba5-4f9a-8e63-0db11ca7f753",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "foo = files.upload()\n",
        "foo = None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b7c668e-7675-498b-9f7b-8276e8c4245a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8b7c668e-7675-498b-9f7b-8276e8c4245a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4iOx8IriAso9",
        "colab_type": "code",
        "outputId": "a1039da8-bddd-4fee-a407-f30058bac0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!chmod 600 kaggle.json\n",
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c 20-newsgroups-ciphertext-challenge\n",
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission.csv.zip to /content\n",
            "\r  0% 0.00/556k [00:00<?, ?B/s]\n",
            "100% 556k/556k [00:00<00:00, 37.7MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 31% 5.00M/16.2M [00:00<00:01, 8.18MB/s]\n",
            "100% 16.2M/16.2M [00:00<00:00, 23.7MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 72% 5.00M/6.98M [00:00<00:00, 9.47MB/s]\n",
            "100% 6.98M/6.98M [00:00<00:00, 12.9MB/s]\n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7eIxC94PA8uc",
        "colab_type": "code",
        "outputId": "c90edb6f-f99b-4acb-f615-c542408e110d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t   test.csv\t train.csv\n",
            "sample_submission.csv.zip  test.csv.zip  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FxoOwB9hAz6q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1sV1mfkhH35N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## process"
      ]
    },
    {
      "metadata": {
        "id": "DWxlh5Z4A-Ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NrJibaDqEkEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbMC_dsQGUZX",
        "colab_type": "code",
        "outputId": "2b19a6a5-0b83-498f-e6d2-0c1d33171df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(train.index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "9m-UcKgEGL-q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filtered = train[train['ciphertext'].str.len() >= 45]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "25wBoFzgGSg4",
        "colab_type": "code",
        "outputId": "96cc8992-ea07-4601-d627-4803531d5cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(filtered.index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38219"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "lM1wN_IMBCEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_train, train_val = train_test_split(filtered, test_size=0.1,\n",
        "                                          random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klGFyufaCYND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#does not actually generate things, call get_list for data (all in memory)\n",
        "class DataGenerator(object):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    \n",
        "    self.length = len(df.index)\n",
        "    print(self.length)\n",
        "\n",
        "    self.ciphertexts = self._transform_ciphers(df['ciphertext'])\n",
        "    \n",
        "    self.difficulties =  df['difficulty'].astype(\"float32\").values\n",
        "    #pd.get_dummies(df['difficulty'], dtype='float32').values\n",
        "    \n",
        "    self.labels = pd.get_dummies(df['target'], dtype='float32').values\n",
        "    \n",
        "    #self.X = np.empty((1, 300, 128, 1), dtype='float32')\n",
        "    #self.m_arange = np.arange(300)\n",
        "  \n",
        "  def _transform_ciphers(self, series):\n",
        "    \n",
        "    #print(series.shape)\n",
        "    np_inputs = np.zeros((self.length, 300), dtype=np.byte)\n",
        "    #for i, e in series.iteritems():\n",
        "    i=0\n",
        "    for _, e in series.iteritems():\n",
        "\n",
        "      encoded = e.encode(\"ascii\", errors='strict')\n",
        "      np_enc = np.frombuffer(encoded, dtype=np.byte)\n",
        "      how_big = np_enc.shape[0]\n",
        "      np_inputs[i, :how_big] = np_enc\n",
        "      \n",
        "      i+=1\n",
        "      \n",
        "    return np_inputs\n",
        "\n",
        "  def get_list(self):\n",
        "    \n",
        "    return [self.ciphertexts[:, :, np.newaxis], self.labels, self.difficulties]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L90UjqprGz8x",
        "colab_type": "code",
        "outputId": "cbb974aa-6075-402f-99e5-cf22055c8906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_gen = DataGenerator(train_train)\n",
        "val_gen = DataGenerator(train_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34397\n",
            "3822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nl79g6iZroFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "        for name in loss_names:\n",
        "            if name in self.keras_model.metrics_names:\n",
        "                continue\n",
        "            layer = self.keras_model.get_layer(name)\n",
        "            self.keras_model.metrics_names.append(name)\n",
        "            self.keras_model.metrics_tensors.append(tf.reduce_mean(\n",
        "                layer.output, keep_dims=True))"
      ]
    },
    {
      "metadata": {
        "id": "AaO0CEAdBumk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iEeDtbmDLo0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss=None,\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# 8 outputs\n",
        "# model.compile(optimizer='rmsprop', loss=[None]*8)\n",
        "\n",
        "# Mask RCNN\n",
        "# Learning rate and momentum\n",
        "# The Mask RCNN paper uses lr=0.02, but on TensorFlow it causes\n",
        "# weights to explode. Likely due to differences in optimizer\n",
        "# implementation.\n",
        "LEARNING_RATE = 0.001\n",
        "LEARNING_MOMENTUM = 0.9\n",
        "GRADIENT_CLIP_NORM = 5.0\n",
        "\n",
        "optimizer = keras.optimizers.SGD(\n",
        "            lr=LEARNING_RATE, momentum=LEARNING_MOMENTUM,\n",
        "            clipnorm=GRADIENT_CLIP_NORM)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=[None]*8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oj6vGJ-NhpuM",
        "colab_type": "code",
        "outputId": "3cee20b1-9874-47e5-b7ce-bf04fa9ee35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)\n",
        "print(model.metrics_tensors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "GowhX-Gxy2Iw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer = model.get_layer(\"loss_1\")\n",
        "model.metrics_names.append(\"loss_1\")\n",
        "model.metrics_tensors.append(tf.reduce_mean(layer.output, keepdims=True))\n",
        "\n",
        "layer = model.get_layer(\"loss_2\")\n",
        "model.metrics_names.append(\"loss_2\")\n",
        "model.metrics_tensors.append(tf.reduce_mean(layer.output, keepdims=True))\n",
        "\n",
        "layer = model.get_layer(\"loss_3\")\n",
        "model.metrics_names.append(\"loss_3\")\n",
        "model.metrics_tensors.append(tf.reduce_mean(layer.output, keepdims=True))\n",
        "\n",
        "layer = model.get_layer(\"loss_4\")\n",
        "model.metrics_names.append(\"loss_4\")\n",
        "model.metrics_tensors.append(tf.reduce_mean(layer.output, keepdims=True))\n",
        "\n",
        "layer = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RJ1Yt5duNsd",
        "colab_type": "code",
        "outputId": "89374637-afc8-4eea-a8ae-b880b09465c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)\n",
        "print(model.metrics_tensors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'loss_1', 'loss_2', 'loss_3', 'loss_4']\n",
            "[<tf.Tensor 'Mean:0' shape=() dtype=float32>, <tf.Tensor 'Mean_1:0' shape=() dtype=float32>, <tf.Tensor 'Mean_2:0' shape=() dtype=float32>, <tf.Tensor 'Mean_3:0' shape=() dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LOqC9yBUB7IB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras.callbacks as KC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiKnGSQBDN-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir ./test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scrwapbCBDil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpt = KC.ModelCheckpoint('./test/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsizW09avB1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir ./logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ng3w4HuEgfRB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tb_call = KC.TensorBoard(log_dir=\"./logs\",\n",
        "                         histogram_freq=0, write_graph=True,\n",
        "                         write_images=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7b6VHZsCRiL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYrRKnFmB9qt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hist = model.fit(x=train_gen.get_list(), y=None, batch_size=32, epochs=i+49,\n",
        "#                  verbose=1, callbacks=[checkpt],\n",
        "#                  validation_data=(val_gen.get_list(), None),\n",
        "#                  shuffle=True, initial_epoch=i)\n",
        "# i += 49\n",
        "print('foo')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jN1LZyZ5f008",
        "colab_type": "code",
        "outputId": "3b5432a9-2157-4ea0-ebb8-37b1a1ad1efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "hist = model.fit(x=train_gen.get_list(), y=None, batch_size=8, epochs=i+10,\n",
        "                 verbose=1, callbacks=[checkpt, tb_call],\n",
        "                 validation_data=(val_gen.get_list(), None),\n",
        "                 shuffle=True, initial_epoch=i)\n",
        "i += 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 34397 samples, validate on 3822 samples\n",
            "Epoch 13/22\n",
            "34397/34397 [==============================] - 325s 9ms/step - loss: 10.6616 - loss_1: 2.6442 - loss_2: 2.6868 - loss_3: 2.6441 - loss_4: 2.6866 - val_loss: 10.6900 - val_loss_1: 2.6695 - val_loss_2: 2.6402 - val_loss_3: 2.6507 - val_loss_4: 2.7297\n",
            "Epoch 14/22\n",
            "34397/34397 [==============================] - 316s 9ms/step - loss: 10.6650 - loss_1: 2.6570 - loss_2: 2.6973 - loss_3: 2.6325 - loss_4: 2.6783 - val_loss: 10.6886 - val_loss_1: 2.6694 - val_loss_2: 2.6395 - val_loss_3: 2.6504 - val_loss_4: 2.7293\n",
            "Epoch 15/22\n",
            "34397/34397 [==============================] - 315s 9ms/step - loss: 10.6900 - loss_1: 2.6470 - loss_2: 2.6943 - loss_3: 2.6557 - loss_4: 2.6930 - val_loss: 10.6890 - val_loss_1: 2.6693 - val_loss_2: 2.6392 - val_loss_3: 2.6507 - val_loss_4: 2.7298\n",
            "Epoch 16/22\n",
            "34397/34397 [==============================] - 316s 9ms/step - loss: 10.6304 - loss_1: 2.6428 - loss_2: 2.6859 - loss_3: 2.6349 - loss_4: 2.6668 - val_loss: 10.6888 - val_loss_1: 2.6707 - val_loss_2: 2.6390 - val_loss_3: 2.6512 - val_loss_4: 2.7280\n",
            "Epoch 17/22\n",
            "34397/34397 [==============================] - 317s 9ms/step - loss: 10.6905 - loss_1: 2.6388 - loss_2: 2.6930 - loss_3: 2.6656 - loss_4: 2.6931 - val_loss: 10.6864 - val_loss_1: 2.6698 - val_loss_2: 2.6386 - val_loss_3: 2.6491 - val_loss_4: 2.7289\n",
            "Epoch 18/22\n",
            "34397/34397 [==============================] - 318s 9ms/step - loss: 10.6682 - loss_1: 2.6470 - loss_2: 2.6828 - loss_3: 2.6455 - loss_4: 2.6929 - val_loss: 10.6814 - val_loss_1: 2.6689 - val_loss_2: 2.6364 - val_loss_3: 2.6492 - val_loss_4: 2.7269\n",
            "Epoch 19/22\n",
            "34397/34397 [==============================] - 318s 9ms/step - loss: 10.6849 - loss_1: 2.6672 - loss_2: 2.6931 - loss_3: 2.6453 - loss_4: 2.6793 - val_loss: 10.6848 - val_loss_1: 2.6690 - val_loss_2: 2.6388 - val_loss_3: 2.6496 - val_loss_4: 2.7274\n",
            "Epoch 20/22\n",
            "34397/34397 [==============================] - 318s 9ms/step - loss: 10.6982 - loss_1: 2.6539 - loss_2: 2.6978 - loss_3: 2.6608 - loss_4: 2.6857 - val_loss: 10.6815 - val_loss_1: 2.6691 - val_loss_2: 2.6366 - val_loss_3: 2.6491 - val_loss_4: 2.7267\n",
            "Epoch 21/22\n",
            "34397/34397 [==============================] - 316s 9ms/step - loss: 10.6691 - loss_1: 2.6527 - loss_2: 2.6745 - loss_3: 2.6573 - loss_4: 2.6845 - val_loss: 10.6847 - val_loss_1: 2.6701 - val_loss_2: 2.6368 - val_loss_3: 2.6510 - val_loss_4: 2.7268\n",
            "Epoch 22/22\n",
            "34397/34397 [==============================] - 317s 9ms/step - loss: 10.6230 - loss_1: 2.6466 - loss_2: 2.6943 - loss_3: 2.6302 - loss_4: 2.6518 - val_loss: 10.6920 - val_loss_1: 2.6705 - val_loss_2: 2.6396 - val_loss_3: 2.6516 - val_loss_4: 2.7302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QtaihSGnCAxY",
        "colab_type": "code",
        "outputId": "274310a5-c1cf-4b09-f023-3d443e1b91b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.callbacks.History"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "DOxXlLkIUFOv",
        "colab_type": "code",
        "outputId": "73c49936-5bb1-4b4e-a83c-2793c53ca010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "hist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17d18eff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "LlY9XZKjNJle",
        "colab_type": "code",
        "outputId": "a172bf69-3a5f-4b45-fa04-e1362b5e593c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights.01-10.78.hdf5  weights.04-10.73.hdf5  weights.07-10.73.hdf5\n",
            "weights.02-10.74.hdf5  weights.05-10.74.hdf5  weights.08-10.73.hdf5\n",
            "weights.03-10.73.hdf5  weights.06-10.73.hdf5  weights.09-10.73.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXASNi2LDY7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv test test1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z9faXoCQu-Zs",
        "colab_type": "code",
        "outputId": "ef682806-b393-4081-9488-114a20ce3a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls logs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "events.out.tfevents.1547934128.4d0da3a2cfc4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jRiW3ON3NKo2",
        "colab_type": "code",
        "outputId": "d3cb969a-cdd2-47f6-bf6d-2fca8de671ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l test/weights.60*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 18688520 Jan 19 05:58 test/weights.60-11.92.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eTFNh3HvUIyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JI_ZuLMKsSXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('test/weights.22-10.69.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktO3Sd5HXiD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv test/weights.09-10.73.hdf5 ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_SSGB7XXnzr",
        "colab_type": "code",
        "outputId": "4a36c7af-293f-437d-8e93-a00b47d1f627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!ls test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights.01-11.95.hdf5  weights.09-10.68.hdf5  weights.17-10.69.hdf5\n",
            "weights.02-10.70.hdf5  weights.10-10.68.hdf5  weights.18-10.68.hdf5\n",
            "weights.03-10.69.hdf5  weights.11-10.68.hdf5  weights.19-10.68.hdf5\n",
            "weights.04-10.69.hdf5  weights.12-10.69.hdf5  weights.20-10.68.hdf5\n",
            "weights.05-10.69.hdf5  weights.13-10.69.hdf5  weights.21-10.68.hdf5\n",
            "weights.06-10.69.hdf5  weights.14-10.69.hdf5  weights.22-10.69.hdf5\n",
            "weights.07-10.68.hdf5  weights.15-10.69.hdf5\n",
            "weights.08-10.69.hdf5  weights.16-10.69.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P6As_z9RXpEr",
        "colab_type": "code",
        "outputId": "140842b3-368d-4f3d-9f32-cec47242cb72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-20 02:25:17--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.199.255.1, 34.238.3.58, 34.204.22.7, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.199.255.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  3.46MB/s    in 1.5s    \n",
            "\n",
            "2019-01-20 02:25:19 (3.46 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h-6Vb8x0E4w0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_RdJVBgVFCqq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pElN7p8zFP2p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "znO9oM-YFGD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfKfEu8WHGwB",
        "colab_type": "code",
        "outputId": "d35f34bf-a04c-4144-e99f-f735bc76b4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pgrep tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Km3KPZv_Hl7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pgrep ngrok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXzvgXSEHFvA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -SIGINT `pgrep ngrok`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hFdQjzEpIj0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -SIGTERM `pgrep tensorboard`"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNBohtdrHVlq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pgrep tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdFDn3NxHkHO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pgrep ngrok"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}