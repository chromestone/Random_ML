{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shake_generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jsNavrBEy6I3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Shakespeare Generator\n",
        "\n",
        "Dependencies:\n",
        "\n",
        "shakespear.txt\n",
        "\n",
        "RNN_weights_128.hdf5\n",
        "\n",
        "your quote.txt (this reads in last 32 chars)"
      ]
    },
    {
      "metadata": {
        "id": "PZAhzMryyjEP",
        "colab_type": "code",
        "outputId": "13335b65-1c85-4221-f06c-eeb0f6547524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vyl0HJMdzV4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44e994f0-7768-43b8-89e3-db709e69fed8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.layers as KL\n",
        "from keras.models import Model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YMBjZlmX2nik",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"shakespear.txt\") as f:\n",
        "\n",
        "  text = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gfldxn_Iy5lk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uniques = list(set(text))\n",
        "# consistency for id generation\n",
        "uniques.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zg4DjDlRzO64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char2id = {k:i for i, k in enumerate(uniques)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wKwc6G4zPRC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "id2char = {i:k for i, k in enumerate(uniques)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNkQnFiA2uyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uGji2JTlzTaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_tensor(char2id, text):\n",
        "  \n",
        "  tensor = np.zeros((len(text), len(char2id)))\n",
        "\n",
        "  for i, e in enumerate(text):\n",
        "    \n",
        "    tensor[i, char2id[e]] = 1\n",
        "\n",
        "  return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "deOAoVzAzX-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_text(id2char, tensor):\n",
        "  \n",
        "  char_list = []\n",
        "  assert len(id2char) == tensor.shape[1]\n",
        "  \n",
        "  first, second = np.where(tensor == 1)\n",
        "  assert first.shape[0] == tensor.shape[0]\n",
        "\n",
        "  for i in range(second.shape[0]):\n",
        "    char_list.append(id2char[second[i]])\n",
        "    \n",
        "  return ''.join(char_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Z5N9x_j0ANk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ARBITRARY_LENGTH = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6nSlogUfzpVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "db41ca0a-f261-4175-ffbe-333c5720abc0"
      },
      "cell_type": "code",
      "source": [
        "input_layer = KL.Input((ARBITRARY_LENGTH, len(char2id)), name=\"the_input\")\n",
        "\n",
        "x = KL.LSTM(62, return_sequences=True, name=\"intermediate\")(input_layer)\n",
        "# used to do softmax but experimenting here\n",
        "x = KL.LSTM(62, activation=\"relu\", name=\"the_output\")(x)\n",
        "\n",
        "model = Model(input_layer, x)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.load_weights('RNN_weights_128.hdf5')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       (None, 32, 62)            0         \n",
            "_________________________________________________________________\n",
            "intermediate (LSTM)          (None, 32, 62)            31000     \n",
            "_________________________________________________________________\n",
            "the_output (LSTM)            (None, 62)                31000     \n",
            "=================================================================\n",
            "Total params: 62,000\n",
            "Trainable params: 62,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AxXdOIM8z4nn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(how_many, put_into_this, char2id, id2char, model):\n",
        "  \n",
        "  assert len(put_into_this) >= ARBITRARY_LENGTH\n",
        "  \n",
        "  for i in range(how_many):\n",
        "    \n",
        "    input_this = to_tensor(char2id, put_into_this[-ARBITRARY_LENGTH:])\n",
        "    max_this = model.predict(input_this[np.newaxis])\n",
        "    put_into_this.append(id2char[np.argmax(max_this)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jFk0Esu70bN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"quote.txt\") as f:\n",
        "  \n",
        "  test = f.read()\n",
        "test_l = list(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t9ebZHOY0u0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict next 256 characters\n",
        "predict(256, test_l, char2id, id2char, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-0kPo1w0wKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "51c0828c-ca40-4fc1-a44c-9221f007c7a8"
      },
      "cell_type": "code",
      "source": [
        "''.join(test_l)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To be, or not to be, that is the title the heavens and the stranger and conceeding, and make her mine\\nTo countles, I cannot speak the chaice.\\n\\nSepord count:\\nI have not besore to the pocked her bearse\\nWe best be pors and are the straight and strange of the pors,\\nWhish sold we are too hand me the provon\\nAnd to the carron to must show an his break of the porth to the great of the prentnger hath not all the prince, I would not to the heart, he do be my to bear her have to the heart, herrell,\\nWhose since the worldest to the true bears the char'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}